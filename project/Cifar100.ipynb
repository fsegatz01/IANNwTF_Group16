{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "g5ldTCY_HV11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c247b509-7212-4b55-898a-49248433b643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nilearn==0.9.2 in /usr/local/lib/python3.9/dist-packages (0.9.2)\n",
            "Requirement already satisfied: nibabel>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (3.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (1.22.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (4.9.2)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (2.27.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.15 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0->nilearn==0.9.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0->nilearn==0.9.2) (2022.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2->nilearn==0.9.2) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2->nilearn==0.9.2) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2->nilearn==0.9.2) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2->nilearn==0.9.2) (1.26.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22->nilearn==0.9.2) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0->nilearn==0.9.2) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nilearn==0.9.2\n",
        "\n",
        "# !pip install keras_cv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from keras import datasets, Sequential\n",
        "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
        "# import keras_cv\n",
        "import keras\n",
        "import datetime\n",
        "\n",
        "# %load_ext tensorboard"
      ],
      "metadata": {
        "id": "xFo3PmgLHoYg"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the data"
      ],
      "metadata": {
        "id": "UW42vfCmHePm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## LOADING CIFAR DATASET #############\n",
        "\n",
        "# cifar, cifar_info = tfds.load(\"cifar100\", as_supervised=True, with_info =True)\n",
        "(train_fab, train_y), (test_fab, test_y)= tf.keras.datasets.cifar100.load_data(label_mode='fine')"
      ],
      "metadata": {
        "id": "lK9Tzny4yD30"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess data"
      ],
      "metadata": {
        "id": "mOUK9-LZHhwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############# PREPROCESS FUNCTION #################\n",
        "\n",
        "def data_pip(cifar10, dataset_type, batch_size):\n",
        "\n",
        "  # data = tf.data.Dataset.from_tensor_slices(data)\n",
        "  cifar10 = cifar10.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
        "  \n",
        "  #sloppy input normalization, just bringing image values from range [0, 255] to [-1, 1]\n",
        "  cifar10 = cifar10.map(lambda img, target: ((img/128.)-1., target))\n",
        "  #create one-hot targets\n",
        "  cifar10 = cifar10.map(lambda img, target: (img, tf.one_hot(target, depth=100)))\n",
        "  #cache this progress in memory, as there is no need to redo it; it is deterministic after all\n",
        "  # cifar10 = cifar10.cache()\n",
        "  #shuffle, batch, prefetch\n",
        "  # cifar10 = cifar10.shuffle(1000)\n",
        "  cifar10 = cifar10.map(lambda img, target: (tf.expand_dims(img, 0), target))\n",
        "  cifar10 = cifar10.batch(32)\n",
        "  return cifar10"
      ],
      "metadata": {
        "id": "x4F5O5dWJopo"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########### PREPROCESS ################\n",
        "\n",
        "issa = tf.data.Dataset.from_tensor_slices((train_fab, train_y))\n",
        "\n",
        "cifar_data = data_pip(issa, 'cifar', 32)\n",
        "print(cifar_data)"
      ],
      "metadata": {
        "id": "Thr67_8RXujP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef64f70-c5fd-406a-e5eb-3c941b52509e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<MapDataset element_spec=(TensorSpec(shape=(1, 32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(1, 100), dtype=tf.float32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "9DfKznMzHuoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############ VISUALIZATION ################\n",
        "\n",
        "# tfds.show_examples(cifar_data, cifar_info)"
      ],
      "metadata": {
        "id": "TmdDuiPPQCQY"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Model"
      ],
      "metadata": {
        "id": "4DphxkMqH3vX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ShYeapWuN9qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############# NO OPTIMIZERS ####################\n",
        "\n",
        "def create_CNN_model():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(input_shape=(32, 32, 3), kernel_size=(2, 2), padding='same', strides=(2, 2), filters=32))\n",
        "    model.add(Conv2D(input_shape=(32, 32, 3), kernel_size=(2, 2), padding='same', strides=(2, 2), filters=32))\n",
        "    model.add(Conv2D(input_shape=(32, 32, 3), kernel_size=(2, 2), padding='same', strides=(2, 2), filters=32))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'))\n",
        "\n",
        "    model.add(Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=64))\n",
        "    model.add(Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=64))\n",
        "    model.add(Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=64))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "\n",
        "    model.compile(loss='CategoricalCrossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "dyU7FYccvMTX"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## CREATE MODEL ###########\n",
        "\n",
        "cnnn_model = create_CNN_model()\n",
        "\n",
        "cnnn_model.summary()"
      ],
      "metadata": {
        "id": "g9Arqc3YZZH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f54d1b-3c1b-41db-e6a6-b0b9daf8784a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 16, 16, 32)        416       \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 8, 8, 32)          4128      \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 4, 4, 32)          4128      \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 4, 4, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 2, 2, 64)          8256      \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 1, 1, 64)          16448     \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 1, 1, 64)          16448     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 1, 1, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               16640     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 112,260\n",
            "Trainable params: 112,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50 Model"
      ],
      "metadata": {
        "id": "CCyZ4MauH-TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############## ResNet50 MODEL  #############\n",
        "\n",
        "resnet_model = tf.keras.applications.resnet.ResNet50(\n",
        "       input_shape=(32,32,3), #.output_shapes()[0],\n",
        "       include_top=True,\n",
        "       weights=None)\n",
        "\n",
        "resnet_model.compile(\n",
        "       optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), #optimizer=tf.keras.optimizers.SGD(lr=0.001),\n",
        "      loss='sparse_categorical_crossentropy', #loss='binary_crossentropy',\n",
        "       metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "XxgC9GMeQkm5"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Test Model\n",
        "weights and tensorboard logging"
      ],
      "metadata": {
        "id": "QfH-1861JCVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set tensorboard \n",
        "# current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# logging_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"./logs/CNN_model/{current_time}\")\n",
        "\n",
        "# Train the model\n",
        "cnnn_model.fit(cifar_data, batch_size=64, epochs=5) #callbacks=[logging_callback]) #batch_size=64, \n",
        "\n",
        "# Test Step\n",
        "test_loss, test_acc = cnnn_model.evaluate(cifar_data)\n",
        "print(\"test accuracy: \", test_acc)\n",
        "\n",
        "# save the weights\n",
        "# cnn_model.save_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# logging with tensorboard\n",
        "# %tensorboard --logdir=\"logs/CNN_model\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT4hTDqByxmp",
        "outputId": "1978bf38-854b-4585-abb6-389bc959de42"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 297s 6ms/step - loss: 4.4117 - accuracy: 0.0285\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 282s 6ms/step - loss: 4.6087 - accuracy: 0.0093\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 279s 6ms/step - loss: 4.6087 - accuracy: 0.0090\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 289s 6ms/step - loss: 4.6087 - accuracy: 0.0090\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 289s 6ms/step - loss: 4.6087 - accuracy: 0.0090\n",
            "50000/50000 [==============================] - 155s 3ms/step - loss: 4.6067 - accuracy: 0.0100\n",
            "test accuracy:  0.009999999776482582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########### LOAD OLD WEIGHTS #########\n",
        "'''\n",
        "# Create a new model instance\n",
        "new_model = create_CNN_model()\n",
        "\n",
        "# Restore the weights\n",
        "new_model.load_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = new_model.evaluate(x_test_cifar, y_test_cifar)\n",
        "print(\"test accuracy: \", acc)'''\n"
      ],
      "metadata": {
        "id": "lO2sMnMLI0e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix"
      ],
      "metadata": {
        "id": "kk2kWW_IIM19"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQXVG0NYLZgL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}