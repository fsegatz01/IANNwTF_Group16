{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "#import datetime\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "#from nilearn import datasets\n",
        "#from nilearn import plotting\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
        "from torchvision import transforms\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.stats import pearsonr as corr\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from keras import datasets, Sequential\n",
        "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab import drive #"
      ],
      "metadata": {
        "id": "QpvXgAYviS4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/fsegatz01/IANNwTF_Group16.git\n",
        "\n",
        "%cd IANNwTF_Group16/project/library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI_lSlkbrWsC",
        "outputId": "dcd98f2c-a9f3-4610-f078-5dd2afe202cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IANNwTF_Group16'...\n",
            "remote: Enumerating objects: 304, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 304 (delta 14), reused 0 (delta 0), pack-reused 277\u001b[K\n",
            "Receiving objects: 100% (304/304), 13.31 MiB | 18.07 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# our own libraries\n",
        "\n",
        "import model_library as ml\n",
        "import data_processing_library as dpl"
      ],
      "metadata": {
        "id": "9dTUDJ4csF1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoTgUVxtVQpl"
      },
      "outputs": [],
      "source": [
        "### CONNECTION TO GOOGLE DRIVE ###\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir (\"drive/MyDrive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "### CONNECTION TO GOOGLE DRIVE ###\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir (\"drive/MyDrive\")\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/algonauts_2023_tutorial_data' \n",
        "parent_submission_dir = '/content/drive/MyDrive/algonauts_2023_challenge_submission' \n",
        "'''"
      ],
      "metadata": {
        "id": "fRmeDXsI8w4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save images as tensors with train_NSD_as_Tensors() and test_NSD_as_Tensors() (in DataProcessing_Library) "
      ],
      "metadata": {
        "id": "a48FyGB85t_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############# PREPROCESS  NSD ###############\n",
        "\n",
        "# we here only use the img data from one person since training the Model on all subjects data takes very long\n",
        "nsd_train_images = dpl.preprocess_NSD(np.load('/content/drive/MyDrive/FinalProject/NSD_Data/nsd_train-images_subj01.npy'))\n",
        "\n",
        "'''\n",
        "\n",
        "### PUT ALL TRAIN IMAGES FROM DIFFERENT SUBJ TOGETHER ###\n",
        "nsd_train_images = np.load('/content/drive/MyDrive/FinalProject/NSD_Data/nsd_train-images_subj01.npy')\n",
        "\n",
        "for i in range(2,9):\n",
        "  nsd_train_images = np.concatenate((nsd_train_images, np.load('/content/drive/MyDrive/FinalProject/NSD_Data/nsd_train-images_subj0{}.npy'.format(i))), axis=0)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "ERNWejiKZxyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######## RELOAD OLD TRAINED MODELS ########\n",
        "\n",
        "\n",
        "### cifar cnn\n",
        "cnn_cifar_model = ml.ConvModel()\n",
        "\n",
        "cnn_cifar_model.compile(loss='categorical_crossentropy',\n",
        "                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                        metrics=['categorical_accuracy'])\n",
        "\n",
        "# Restore the weights\n",
        "cnn_cifar_model.load_weights('/checkpoints/cnn_cifar_model')\n",
        "\n",
        "\n",
        "##############################################\n",
        "\n",
        "### eco cnn\n",
        "cnn_eco_model = ml.ConvModel()\n",
        "\n",
        "cnn_eco_model.compile(loss='categorical_crossentropy',\n",
        "                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                        metrics=['categorical_accuracy'])\n",
        "\n",
        "# Restore the weights\n",
        "cnn_eco_model.load_weights('/checkpoints/cnn_eco_model')\n",
        "\n",
        "\n",
        "##############################################\n",
        "\n",
        "### cifar resnet50\n",
        "resnet_cifar_model = ml.ResNetModel()\n",
        "\n",
        "resnet_cifar_model.compile(loss='categorical_crossentropy',\n",
        "                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                        metrics=['categorical_accuracy'])\n",
        "\n",
        "# Restore the weights\n",
        "resnet_cifar_model.load_weights('{checkpoints/resnet_cifar_model')\n",
        "\n",
        "\n",
        "#############################################\n",
        "\n",
        "### eco resnet50\n",
        "resnet_eco_model = ml.ResNetModel()\n",
        "\n",
        "resnet_eco_model.compile(loss='categorical_crossentropy',\n",
        "                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                        metrics=['categorical_accuracy'])\n",
        "\n",
        "# Restore the weights\n",
        "resnet_cifar_model.load_weights('{checkpoints/resnet_eco_model')"
      ],
      "metadata": {
        "id": "Ta4cMR8_7ZcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_output_to_input(model, layer_number, data):\n",
        "\n",
        "  ''' takes the output from the layer layer_number in model\n",
        "  when runnindg data through'''\n",
        "      \n",
        "    get_layer_output = K.function([model.layers[0].input],\n",
        "                                      [model.layers[layer_number].output])\n",
        "    layer_output = get_layer_output([data])[0]\n",
        "    hidden_layer_outputs_flat = tf.keras.layers.Flatten()(layer_output)\n",
        "\n",
        "    return hidden_layer_outputs_flat\n",
        "\n",
        "\n",
        "cnn_features = resnet_output_to_input(cnn_cifar_model, 3, nsd_train_images)\n",
        "\n",
        "\n",
        "def resnet_output_to_input(model, layer_number, data):\n",
        "\n",
        "    ''' takes the output from the layer layer_number in model\n",
        "    when runnindg data through'''\n",
        "      \n",
        "    get_layer_output = K.function([model.resnet50.input],\n",
        "                                      [model.resnet50.layers[layer_number].output])\n",
        "    layer_output = get_layer_output([data])[0]\n",
        "    hidden_layer_outputs_flat = tf.keras.layers.Flatten()(layer_output)\n",
        "\n",
        "    return hidden_layer_outputs_flat\n"
      ],
      "metadata": {
        "id": "JFoWQzFnb_J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit linear regressions on the training data\n",
        "linReg_lh = LinearRegression().fit(cnn_features, np.load('/content/drive/MyDrive/algonauts_2023_tutorial_data/subj01/training_split/training_fmri/lh_training_fmri.npy'))\n",
        "linReg_rh = LinearRegression().fit(cnn_features, np.load('/content/drive/MyDrive/algonauts_2023_tutorial_data/subj01/training_split/training_fmri/rh_training_fmri.npy'))\n"
      ],
      "metadata": {
        "id": "ajoqejjAccse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "#add slightly transformed/rotated copies of already included data\n",
        "augmentation_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  tf.keras.layers.RandomRotation(0.1),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "A6ffZfmy30iV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}