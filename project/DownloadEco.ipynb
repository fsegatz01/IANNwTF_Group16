{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5ldTCY_HV11",
        "outputId": "ca085600-682e-4ba1-8600-75f52b2de3de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nilearn==0.9.2 in /usr/local/lib/python3.9/dist-packages (0.9.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (1.10.1)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (1.22.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (4.9.2)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (1.4.4)\n",
            "Requirement already satisfied: nibabel>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (3.0.2)\n",
            "Requirement already satisfied: joblib>=0.15 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (1.1.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.9/dist-packages (from nilearn==0.9.2) (1.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0->nilearn==0.9.2) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0->nilearn==0.9.2) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2->nilearn==0.9.2) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2->nilearn==0.9.2) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2->nilearn==0.9.2) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2->nilearn==0.9.2) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22->nilearn==0.9.2) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0->nilearn==0.9.2) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nilearn==0.9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFo3PmgLHoYg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
        "\n",
        "from google.colab import drive\n",
        "import h5py\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "\n",
        "import datetime\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW42vfCmHePm"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOFmgNiKebd2",
        "outputId": "b61f24cd-f3b6-44c7-d72d-0e87cfb3428e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir (\"drive/MyDrive\")\n",
        "\n",
        "filename = \"/content/drive/MyDrive/miniecoset_100obj_64px.h5\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class HDF5Sequence(tf.keras.utils.Sequence):\n",
        "    def __init__(self, filename, batch_size):\n",
        "        self.batch_size = batch_size\n",
        "        with h5py.File(filename, 'r') as f:\n",
        "            self.length = f['train']['labels'].shape[0]\n",
        "        self.file = filename\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(tf.math.ceil(self.length / float(self.batch_size)))\n",
        "\n",
        "    def __gettrain__(self, idx):\n",
        "        with h5py.File(self.file, 'r') as f:\n",
        "            start_idx = idx * self.batch_size\n",
        "            end_idx = (idx + 1) * self.batch_size\n",
        "            train_img = f['train']['data'][start_idx:end_idx]\n",
        "            train_labels = f['train']['labels'][start_idx:end_idx]\n",
        "        return train_img, train_labels\n",
        "\n",
        "    def __gettest__(self, idx):\n",
        "        with h5py.File(self.file, 'r') as f:\n",
        "            start_idx = idx * self.batch_size\n",
        "            end_idx = (idx + 1) * self.batch_size\n",
        "            test_img = f['test']['data'][start_idx:end_idx]\n",
        "            test_labels = f['test']['labels'][start_idx:end_idx]\n",
        "        return test_img, test_labels\n"
      ],
      "metadata": {
        "id": "MhFphWZlyKi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the path to your hdf5 file and the batch size\n",
        "filename = \"/content/drive/MyDrive/miniecoset_100obj_64px.h5\"\n",
        "batch_size = 32\n",
        "\n",
        "# create a Sequence object\n",
        "hdf5_sequence = HDF5Sequence(filename, batch_size)\n",
        "\n",
        "# define the output signature of the generator\n",
        "output_signature = (\n",
        "    tf.TensorSpec(shape=(None, 32, 32, 1), dtype=tf.float32),\n",
        "    tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "#data augmentation\n",
        "#add slightly transformed copies of already included data\n",
        "augmentation_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  tf.keras.layers.RandomRotation(0.1),\n",
        "])\n"
      ],
      "metadata": {
        "id": "Snmvu39INTm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tf dataset from the generator\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    generator=hdf5_sequence.__gettrain__,\n",
        "    output_signature=output_signature,\n",
        "    args=(0,)\n",
        ")\n"
      ],
      "metadata": {
        "id": "-RPHSZE5N2oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create a tf dataset from the generator\n",
        "test_dataset = tf.data.Dataset.from_generator(\n",
        "    generator=hdf5_sequence.__gettest__,\n",
        "    output_signature=output_signature,\n",
        "    args=(0,)\n",
        ")"
      ],
      "metadata": {
        "id": "UMM6GKJORxKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data, augmentation_model):\n",
        "    # perform any additional preprocessing steps on the dataset as needed\n",
        "    data = data.map(lambda x, y: (tf.image.convert_image_dtype(x, tf.float32), y))\n",
        "\n",
        "\n",
        "    data = data.map(lambda img, target: (img, tf.one_hot(target, depth=100)))\n",
        "\n",
        "    data = data.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
        "    #sloppy input normalization, just bringing image values from range [0, 255] to [-1, 1]\n",
        "    data = data.map(lambda img, target: ((img/128.)-1., target))\n",
        "\n",
        "    # resize_layer = Resizing(32, 32)\n",
        "\n",
        "    # Apply the Resizing layer to the datasets\n",
        "    # data = data.map(lambda img, target: (resize_layer(img), target))\n",
        "\n",
        "    #cache this progress in memory\n",
        "    data = data.cache()\n",
        "    data = data.shuffle(1000)\n",
        "    # data = data.batch(32)\n",
        "    data = data.prefetch(20)\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "jWw0j1C1NVxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = preprocess(train_dataset, augmentation_model = augmentation_model)\n",
        "test_data = preprocess(test_dataset, augmentation_model = augmentation_model)"
      ],
      "metadata": {
        "id": "QJ2AbordOQ0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02131457-b993-4e15-c377-b631daadfe4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CNN Model"
      ],
      "metadata": {
        "id": "kai1MvU6IbE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######## NEUES MODEL yaYYYY ##########\n",
        "\n",
        "#from tensorflow.python.framework.importer import import_graph_def_for_function\n",
        "\n",
        "class BasicConv(tf.keras.Model):\n",
        "    def __init__(self, L2_reg=0, dropout_rate=0, batch_norm=False): # penalties, dropout, batch normalization\n",
        "\n",
        "        \"\"\" \n",
        "        subclass of the tf.keras.Model class, creates metrics\n",
        "        Args:\n",
        "            L2_reg(float) = regularizer that applies a L2 regularization penalty\n",
        "            dropout_rate(float) = sets input units to 0 with a frequency dropout_rate\n",
        "            batch_norm(bool): using tf.keras.layers.BatchNormalization() or None\n",
        "        \"\"\"  \n",
        "        super(BasicConv, self).__init__()\n",
        "\n",
        "        kernel_regularizer = tf.keras.regularizers.L2(L2_reg) if L2_reg else None # Wer das liest ist blöd\n",
        "\n",
        "        self.dropout_rate = dropout_rate\n",
        "        if self.dropout_rate: # include dropout_rate\n",
        "           self.dropout_layer = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "        self.batch_norm = batch_norm\n",
        "        if self.batch_norm: # include dropout_rate\n",
        "           self.batch_norm_layer = tf.keras.layers.BatchNormalization()\n",
        "        \n",
        "        # creating a list of layers\n",
        "        self.layer_list = [tf.keras.layers.Conv2D(input_shape=(32, 32, 3), kernel_size=(2, 2), padding='same', strides=(2, 2), filters=32),\n",
        "                           #tf.keras.layers.Conv2D(input_shape=(32, 32, 3), kernel_size=(2, 2), padding='same', strides=(2, 2), filters=32),\n",
        "                           #tf.keras.layers.Conv2D(input_shape=(32, 32, 3), kernel_size=(2, 2), padding='same', strides=(2, 2), filters=32),\n",
        "                           tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
        "                           tf.keras.layers.Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=64),\n",
        "                           #tf.keras.layers.Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=64),\n",
        "                           #tf.keras.layers.Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=64),\n",
        "                           tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
        "                           tf.keras.layers.Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=128),\n",
        "                           #tf.keras.layers.Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=32),\n",
        "                           #tf.keras.layers.Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=32),\n",
        "                           tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
        "                           #tf.keras.layers.Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=256), #neu\n",
        "                           #tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'), #neu\n",
        "                           tf.keras.layers.Flatten(),\n",
        "                           tf.keras.layers.Dense(256, activation='relu'),\n",
        "                           tf.keras.layers.Dense(128, activation='relu'),\n",
        "                           tf.keras.layers.Dense(100, activation='softmax')]\n",
        "\n",
        "        if batch_norm:\n",
        "          # layer_list with BatchNorm\n",
        "          self.layer_list = [tf.keras.layers.Conv2D(input_shape=(32, 32, 3), kernel_size=(2, 2), padding='same', strides=(2, 2), filters=32),\n",
        "                              tf.keras.layers.BatchNormalization(),\n",
        "                              tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
        "                              tf.keras.layers.BatchNormalization(),\n",
        "                              tf.keras.layers.Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=64),\n",
        "                              tf.keras.layers.BatchNormalization(),\n",
        "                              tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
        "                              tf.keras.layers.BatchNormalization(),\n",
        "                              tf.keras.layers.Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=128),\n",
        "                              tf.keras.layers.BatchNormalization(),\n",
        "                              tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
        "                              tf.keras.layers.BatchNormalization(),\n",
        "                              tf.keras.layers.Flatten(),\n",
        "                              tf.keras.layers.BatchNormalization(),\n",
        "                              tf.keras.layers.Dense(256, activation='relu'),\n",
        "                              tf.keras.layers.BatchNormalization(),\n",
        "                              tf.keras.layers.Dense(128, activation='relu'),\n",
        "                              tf.keras.layers.BatchNormalization(),\n",
        "                              tf.keras.layers.Dense(100, activation='softmax')]\n",
        "\n",
        "        '''\n",
        "        if batch_norm: # if batch_norm, add tf.keras.layers.BatchNormalization() layers\n",
        "          self.layer_list = self.batched_layer_list\n",
        "        else:\n",
        "          self.layer_list = self.normal_layer_list\n",
        "        '''\n",
        "\n",
        "        # optimizer, loss function and metrics\n",
        "        self.metrics_list = [tf.keras.metrics.Mean(name=\"loss\"),\n",
        "                             tf.keras.metrics.CategoricalAccuracy(name=\"acc\")]\n",
        "        \n",
        "\n",
        "        self.loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) # optimizer Adam\n",
        "\n",
        "            \n",
        "    def call(self, x, training=False):\n",
        "\n",
        "      ind=0  \n",
        "      for layer in self.layer_list[:-1]:\n",
        "\n",
        "        if self.batch_norm==True:\n",
        "          \n",
        "          # for every second layer <-> batchNorm layer\n",
        "          if ind%2==1:\n",
        "            ind+=1\n",
        "            x = layer(x, training)\n",
        "          else:\n",
        "            ind+=1\n",
        "            x = layer(x)\n",
        "        \n",
        "        else:\n",
        "          x = layer(x)\n",
        "\n",
        "        if self.dropout_rate:\n",
        "            x = self.dropout_layer(x, training)\n",
        "\n",
        "      return self.layer_list[-1](x)\n",
        "\n",
        "    \n",
        "    # 3. metrics property\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return self.metrics_list\n",
        "        # return a list with all metrics in the model\n",
        "\n",
        "    # 4. reset all metrics objects\n",
        "    def reset_metrics(self):\n",
        "        \"\"\"\n",
        "        return a list with all metrics in the model\n",
        "        \"\"\"\n",
        "        for metric in self.metrics:\n",
        "            metric.reset_states()\n",
        "\n",
        "    # added to get frobenius graph\n",
        "    def compute_frobenius(self):\n",
        "        \"\"\"compute and return frobenius norm\n",
        "        Returns:\n",
        "            (tensor): frobenius norm\n",
        "        \"\"\"\n",
        "        frobenius_norm = tf.zeros((1,))\n",
        "        for var in self.trainable_variables:\n",
        "            frobenius_norm += tf.norm(var, ord=\"euclidean\")\n",
        "        return frobenius_norm\n",
        "\n",
        "    # 5. train step method\n",
        "    def train_step(self, data):\n",
        "        \"\"\"\n",
        "        training the network for once\n",
        "        Args:\n",
        "            data: input data (image with target)\n",
        "        Returns:\n",
        "            Return a dictionary mapping metric names to current value\n",
        "        \"\"\"\n",
        "\n",
        "        img, label = data\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            output = self(img, training=True)\n",
        "            #label = tf.reshape(label, output.shape)\n",
        "            #loss = self.loss_function(label, output)\n",
        "            loss = self.loss_function(label, output) + tf.reduce_sum(self.losses)\n",
        "            \n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        \n",
        "        # update the state of the metrics according to loss and accuracy\n",
        "        self.metrics[0].update_state(loss)\n",
        "        self.metrics[1].update_state(label, output)\n",
        "\n",
        "        # return a dictionary with metric names as keys and metric results as values\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "\n",
        "    # 6. test_step method\n",
        "    def test_step(self, data):\n",
        "\n",
        "        \"\"\"\n",
        "        testing the network for once\n",
        "        Args:\n",
        "            data: input data (image with target)\n",
        "        Returns:\n",
        "            Return a dictionary mapping metric names to current value\n",
        "        \"\"\"\n",
        "\n",
        "        img, label = data\n",
        "        output = self(img, training=False)\n",
        "        #label = tf.reshape(label, output.shape)\n",
        "        #loss = self.loss_function(label, output)\n",
        "        loss = self.loss_function(label, output) + tf.reduce_sum(self.losses)\n",
        "\n",
        "        # update the state of the metrics according to loss and accuracy\n",
        "        self.metrics[0].update_state(loss)\n",
        "        self.metrics[1].update_state(label, output)\n",
        "        #print({m.name: m.result() for m in self.metrics})\n",
        "\n",
        "        # return a dictionary with metric names as keys and metric results as values\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "metadata": {
        "id": "VPztLcWRz7BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "HKGbuMECIk7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mymodel = BasicConv(batch_norm=True)\n",
        "\n",
        "mymodel.compile(loss='categorical_crossentropy',\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "Z5IHj6bSIfPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Train the model\n",
        "mymodel.fit(train_data, epochs=3)\n",
        "\n",
        "# Test Step\n",
        "test_loss, test_acc = mymodel.evaluate(test_data)\n",
        "print(\"test accuracy: \", test_acc)"
      ],
      "metadata": {
        "id": "tdaB4xSkIfHf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3460728b-210f-4264-ed49-150adcc9ba11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-828b193f6d8d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmymodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Test Step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32), but the yielded element was [[[[246 250 249]\n   [247 251 250]\n   [247 251 250]\n   ...\n   [253 255 254]\n   [253 255 254]\n   [252 254 253]]\n\n  [[247 251 250]\n   [249 252 251]\n   [249 252 251]\n   ...\n   [254 255 254]\n   [254 255 254]\n   [253 255 254]]\n\n  [[250 252 251]\n   [251 253 252]\n   [251 253 253]\n   ...\n   [255 255 255]\n   [255 255 255]\n   [255 255 255]]\n\n  ...\n\n  [[137 118  40]\n   [137 123  45]\n   [139 123  45]\n   ...\n   [156 172 185]\n   [167 183 197]\n   [159 175 190]]\n\n  [[132 113  36]\n   [137 118  41]\n   [143 126  45]\n   ...\n   [150 166 179]\n   [166 182 196]\n   [160 176 191]]\n\n  [[122 110  31]\n   [128 113  37]\n   [141 123  44]\n   ...\n   [144 158 170]\n   [164 179 190]\n   [159 174 185]]]\n\n\n [[[ 49  36  22]\n   [ 46  33  20]\n   [ 44  32  20]\n   ...\n   [ 30  18  11]\n   [ 45  30  21]\n   [ 58  45  29]]\n\n  [[ 45  33  22]\n   [ 44  32  20]\n   [ 42  30  18]\n   ...\n   [ 28  18  10]\n   [ 39  26  17]\n   [ 54  42  26]]\n\n  [[ 44  32  21]\n   [ 43  31  19]\n   [ 40  28  16]\n   ...\n   [ 26  16  10]\n   [ 38  25  16]\n   [ 52  40  27]]\n\n  ...\n\n  [[ 42  30  18]\n   [ 40  29  16]\n   [ 39  27  15]\n   ...\n   [ 73  60  44]\n   [ 80  67  50]\n   [ 92  76  59]]\n\n  [[ 41  30  18]\n   [ 40  28  16]\n   [ 42  29  17]\n   ...\n   [ 73  60  43]\n   [ 81  68  51]\n   [ 91  76  60]]\n\n  [[ 42  30  18]\n   [ 41  28  17]\n   [ 47  33  22]\n   ...\n   [ 72  58  42]\n   [ 78  65  48]\n   [ 86  75  57]]]\n\n\n [[[255 255 255]\n   [244 244 241]\n   [170 162 151]\n   ...\n   [255 255 255]\n   [255 255 255]\n   [255 255 255]]\n\n  [[255 255 255]\n   [206 202 195]\n   [125 112  97]\n   ...\n   [255 255 255]\n   [255 255 255]\n   [255 255 255]]\n\n  [[254 254 254]\n   [175 166 159]\n   [105  91  73]\n   ...\n   [255 255 255]\n   [255 255 255]\n   [255 255 255]]\n\n  ...\n\n  [[  8   8   7]\n   [  9   6   5]\n   [ 30  21  17]\n   ...\n   [  7   7   7]\n   [  7   7   7]\n   [  7   8   8]]\n\n  [[  7   7   7]\n   [  5   6   6]\n   [ 20  16  17]\n   ...\n   [  7   7   7]\n   [  7   7   7]\n   [  8   8   8]]\n\n  [[  7   7   7]\n   [  6   6   6]\n   [  8   9  10]\n   ...\n   [  7   7   7]\n   [  7   7   7]\n   [  7   7   7]]]\n\n\n ...\n\n\n [[[239 244 242]\n   [227 222 222]\n   [139  52  43]\n   ...\n   [178  75  75]\n   [235 223 224]\n   [236 242 239]]\n\n  [[238 244 244]\n   [226 221 224]\n   [138  52  44]\n   ...\n   [177  72  73]\n   [234 221 222]\n   [236 242 239]]\n\n  [[242 242 246]\n   [226 220 224]\n   [127  49  41]\n   ...\n   [176  72  72]\n   [234 221 222]\n   [236 242 239]]\n\n  ...\n\n  [[241 243 245]\n   [220 221 222]\n   [ 50  49  39]\n   ...\n   [139 137 133]\n   [249 251 250]\n   [241 243 242]]\n\n  [[240 243 243]\n   [218 217 217]\n   [ 52  47  36]\n   ...\n   [164 154 145]\n   [247 250 250]\n   [242 244 243]]\n\n  [[238 245 242]\n   [216 212 209]\n   [103  69  52]\n   ...\n   [178 159 145]\n   [246 249 250]\n   [243 245 243]]]\n\n\n [[[ 92  75 115]\n   [ 93  76 114]\n   [ 82  67 101]\n   ...\n   [ 96  87 118]\n   [ 93  85 116]\n   [ 92  83 111]]\n\n  [[ 94  79 118]\n   [ 94  78 115]\n   [ 83  67 101]\n   ...\n   [ 96  87 115]\n   [ 93  84 114]\n   [ 92  84 113]]\n\n  [[ 94  81 119]\n   [ 95  79 117]\n   [ 83  67 101]\n   ...\n   [ 95  86 116]\n   [ 92  84 112]\n   [ 93  84 112]]\n\n  ...\n\n  [[214 225 226]\n   [203 205 200]\n   [159 166 165]\n   ...\n   [ 62  52  50]\n   [ 72  64  61]\n   [110  97  94]]\n\n  [[211 216 216]\n   [202 205 202]\n   [158 161 159]\n   ...\n   [ 72  62  58]\n   [ 76  66  63]\n   [105  96  92]]\n\n  [[210 208 203]\n   [193 190 185]\n   [155 157 157]\n   ...\n   [123 122 121]\n   [125 124 123]\n   [132 132 131]]]\n\n\n [[[ 65  49  44]\n   [ 72  54  39]\n   [104  75  46]\n   ...\n   [ 92  73  66]\n   [ 89  73  70]\n   [ 75  60  74]]\n\n  [[ 59  47  20]\n   [ 66  50  11]\n   [107  70  19]\n   ...\n   [ 85  78  78]\n   [ 64  57  78]\n   [ 60  53  89]]\n\n  [[ 66  52  28]\n   [ 70  54  18]\n   [109  73  24]\n   ...\n   [ 62  64  86]\n   [ 56  55  92]\n   [ 60  58 108]]\n\n  ...\n\n  [[ 89  76  34]\n   [108  86  33]\n   [121  97  32]\n   ...\n   [ 64  47  27]\n   [ 64  47  26]\n   [ 63  46  26]]\n\n  [[ 83  70  21]\n   [ 92  78  25]\n   [ 96  75  25]\n   ...\n   [ 47  29  14]\n   [ 61  40  23]\n   [ 66  42  24]]\n\n  [[ 79  66  18]\n   [ 88  77  27]\n   [ 89  80  29]\n   ...\n   [ 46  29  15]\n   [ 55  33  17]\n   [ 66  39  22]]]].\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1045, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/util/nest.py\", line 377, in flatten_up_to\n    assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/util/nest.py\", line 278, in assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'ndarray'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1047, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32), but the yielded element was [[[[246 250 249]\n   [247 251 250]\n   [247 251 250]\n   ...\n   [253 255 254]\n   [253 255 254]\n   [252 254 253]]\n\n  [[247 251 250]\n   [249 252 251]\n   [249 252 251]\n   ...\n   [254 255 254]\n   [254 255 254]\n   [253 255 254]]\n\n  [[250 252 251]\n   [251 253 252]\n   [251 253 253]\n   ...\n   [255 255 255]\n   [255 255 255]\n   [255 255 255]]\n\n  ...\n\n  [[137 118  40]\n   [137 123  45]\n   [139 123  45]\n   ...\n   [156 172 185]\n   [167 183 197]\n   [159 175 190]]\n\n  [[132 113  36]\n   [137 118  41]\n   [143 126  45]\n   ...\n   [150 166 179]\n   [166 182 196]\n   [160 176 191]]\n\n  [[122 110  31]\n   [128 113  37]\n   [141 123  44]\n   ...\n   [144 158 170]\n   [164 179 190]\n   [159 174 185]]]\n\n\n [[[ 49  36  22]\n   [ 46  33  20]\n   [ 44  32  20]\n   ...\n   [ 30  18  11]\n   [ 45  30  21]\n   [ 58  45  29]]\n\n  [[ 45  33  22]\n   [ 44  32  20]\n   [ 42  30  18]\n   ...\n   [ 28  18  10]\n   [ 39  26  17]\n   [ 54  42  26]]\n\n  [[ 44  32  21]\n   [ 43  31  19]\n   [ 40  28  16]\n   ...\n   [ 26  16  10]\n   [ 38  25  16]\n   [ 52  40  27]]\n\n  ...\n\n  [[ 42  30  18]\n   [ 40  29  16]\n   [ 39  27  15]\n   ...\n   [ 73  60  44]\n   [ 80  67  50]\n   [ 92  76  59]]\n\n  [[ 41  30  18]\n   [ 40  28  16]\n   [ 42  29  17]\n   ...\n   [ 73  60  43]\n   [ 81  68  51]\n   [ 91  76  60]]\n\n  [[ 42  30  18]\n   [ 41  28  17]\n   [ 47  33  22]\n   ...\n   [ 72  58  42]\n   [ 78  65  48]\n   [ 86  75  57]]]\n\n\n [[[255 255 255]\n   [244 244 241]\n   [170 162 151]\n   ...\n   [255 255 255]\n   [255 255 255]\n   [255 255 255]]\n\n  [[255 255 255]\n   [206 202 195]\n   [125 112  97]\n   ...\n   [255 255 255]\n   [255 255 255]\n   [255 255 255]]\n\n  [[254 254 254]\n   [175 166 159]\n   [105  91  73]\n   ...\n   [255 255 255]\n   [255 255 255]\n   [255 255 255]]\n\n  ...\n\n  [[  8   8   7]\n   [  9   6   5]\n   [ 30  21  17]\n   ...\n   [  7   7   7]\n   [  7   7   7]\n   [  7   8   8]]\n\n  [[  7   7   7]\n   [  5   6   6]\n   [ 20  16  17]\n   ...\n   [  7   7   7]\n   [  7   7   7]\n   [  8   8   8]]\n\n  [[  7   7   7]\n   [  6   6   6]\n   [  8   9  10]\n   ...\n   [  7   7   7]\n   [  7   7   7]\n   [  7   7   7]]]\n\n\n ...\n\n\n [[[239 244 242]\n   [227 222 222]\n   [139  52  43]\n   ...\n   [178  75  75]\n   [235 223 224]\n   [236 242 239]]\n\n  [[238 244 244]\n   [226 221 224]\n   [138  52  44]\n   ...\n   [177  72  73]\n   [234 221 222]\n   [236 242 239]]\n\n  [[242 242 246]\n   [226 220 224]\n   [127  49  41]\n   ...\n   [176  72  72]\n   [234 221 222]\n   [236 242 239]]\n\n  ...\n\n  [[241 243 245]\n   [220 221 222]\n   [ 50  49  39]\n   ...\n   [139 137 133]\n   [249 251 250]\n   [241 243 242]]\n\n  [[240 243 243]\n   [218 217 217]\n   [ 52  47  36]\n   ...\n   [164 154 145]\n   [247 250 250]\n   [242 244 243]]\n\n  [[238 245 242]\n   [216 212 209]\n   [103  69  52]\n   ...\n   [178 159 145]\n   [246 249 250]\n   [243 245 243]]]\n\n\n [[[ 92  75 115]\n   [ 93  76 114]\n   [ 82  67 101]\n   ...\n   [ 96  87 118]\n   [ 93  85 116]\n   [ 92  83 111]]\n\n  [[ 94  79 118]\n   [ 94  78 115]\n   [ 83  67 101]\n   ...\n   [ 96  87 115]\n   [ 93  84 114]\n   [ 92  84 113]]\n\n  [[ 94  81 119]\n   [ 95  79 117]\n   [ 83  67 101]\n   ...\n   [ 95  86 116]\n   [ 92  84 112]\n   [ 93  84 112]]\n\n  ...\n\n  [[214 225 226]\n   [203 205 200]\n   [159 166 165]\n   ...\n   [ 62  52  50]\n   [ 72  64  61]\n   [110  97  94]]\n\n  [[211 216 216]\n   [202 205 202]\n   [158 161 159]\n   ...\n   [ 72  62  58]\n   [ 76  66  63]\n   [105  96  92]]\n\n  [[210 208 203]\n   [193 190 185]\n   [155 157 157]\n   ...\n   [123 122 121]\n   [125 124 123]\n   [132 132 131]]]\n\n\n [[[ 65  49  44]\n   [ 72  54  39]\n   [104  75  46]\n   ...\n   [ 92  73  66]\n   [ 89  73  70]\n   [ 75  60  74]]\n\n  [[ 59  47  20]\n   [ 66  50  11]\n   [107  70  19]\n   ...\n   [ 85  78  78]\n   [ 64  57  78]\n   [ 60  53  89]]\n\n  [[ 66  52  28]\n   [ 70  54  18]\n   [109  73  24]\n   ...\n   [ 62  64  86]\n   [ 56  55  92]\n   [ 60  58 108]]\n\n  ...\n\n  [[ 89  76  34]\n   [108  86  33]\n   [121  97  32]\n   ...\n   [ 64  47  27]\n   [ 64  47  26]\n   [ 63  46  26]]\n\n  [[ 83  70  21]\n   [ 92  78  25]\n   [ 96  75  25]\n   ...\n   [ 47  29  14]\n   [ 61  40  23]\n   [ 66  42  24]]\n\n  [[ 79  66  18]\n   [ 88  77  27]\n   [ 89  80  29]\n   ...\n   [ 46  29  15]\n   [ 55  33  17]\n   [ 66  39  22]]]].\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_4328]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "############## ResNet50 MODEL  #############\n",
        "\n",
        "resnet_model = tf.keras.applications.resnet.ResNet50(\n",
        "       input_shape=(32,32,3), #.output_shapes()[0],\n",
        "       include_top=True,\n",
        "       weights=None,\n",
        "       classes=100)\n",
        "\n",
        "resnet_model.compile(\n",
        "       optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), #optimizer=tf.keras.optimizers.SGD(lr=0.001),\n",
        "      loss='categorical_crossentropy', #loss='binary_crossentropy',\n",
        "       metrics=['categorical_accuracy'])\n",
        "\n",
        "\n",
        "resnet_model.fit(train_cifar, batch_size=64, epochs=1) #callbacks=[logging_callback]) #batch_size=64, \n",
        "\n",
        "# Test Step\n",
        "test_loss, test_acc = resnet_model.evaluate(test_cifar)\n",
        "print(\"test accuracy: \", test_acc)\n"
      ],
      "metadata": {
        "id": "A_hG7LBh4djL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load an hdf5 file into tensorflow as a tf.data.Dataset object, you should **define a tf.keras.utils.Sequence object** that reads the images and their labels. You can then treat this Sequence object **as a generator** and turn it into a tf dataset with **tf.data.Dataset.from_generator**(...) by specifying the output signature (dtypes and shapes of the returns of the get_item method in the Sequence object that you need to define. All this sounds more complicated than it is and you can look at examples for this online."
      ],
      "metadata": {
        "id": "RcJbrMpPiWSS"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}